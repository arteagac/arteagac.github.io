<br />
<div class="w3-white w3-text-grey w3-card-4">
	<a href="https://nbviewer.jupyter.org/url/arteagac.github.io/blog/lime_image.ipynb" style="text-decoration: none;">
		<div class="w3-display-container">
			<img src="blog/lime_image/img/lime_banner.png" style="width:100%" alt="lime">
		</div>
		<div class="w3-container">
		<h3 class="w3-text-grey">Interpretable Machine Learning with LIME for Image Classification</h3>
		<p class="w3-text-grey">Sep-16-2019</p>
		<p class="w3-text-grey">This is a step by step tutorial with python code of how LIME works for explanations of image classifications. The python code is provided in a notebook that you can dowload and try by your self. To try it, you can use for example the google colab environment so you don't need to install anything in your computer. </p>
		</div>
	</a>
</div>
<br />
<div class="w3-white w3-text-grey w3-card-4">
	<a href="https://nbviewer.jupyter.org/url/arteagac.github.io/blog/lime.ipynb" style="text-decoration: none;">
		<div class="w3-display-container">
			<img src="blog/lime/img/banner.png" style="width:100%" alt="lime">
		</div>
		<div class="w3-container">
		<h3 class="w3-text-grey">Interpretable Machine Learning with LIME</h3>
		<p class="w3-text-grey">Sep-16-2019</p>
		<p class="w3-text-grey">In this step by step guide with python code, we will study the details behind a popular technique for interpretable machine learning called LIME (Local Interpretable Model-agnostic Explanations). This technique was proposed by Rubiero et. al. in their paper "Why should I trust you?: Explaining the predictions of any classifier" on 2016. The example developed in this post is for explanations of tabular data. </p>
		</div>
	</a>
</div>
<br />